2.5GPU 计算设备调度

GPU 计算设备在并行处理大量的工作项时非常的高效，整个过程对
应用程序是透明的。每个 GPU 计算设备使用大量的 wavefronts 
来隐藏内存访问的延迟，在特定的计算单元中，当当前的
wavefront 在等待内存访问完成过程中，通过资源调度器切换到一
个活动的 wavefront 执行。

隐藏内存访问的延迟要求每个工作项包含大量的 ALU 操作，当在内
存加载/存储时。

下图显示了在单个计算单元中，简化了的 wavefronts 的执行
时序。在 time 0 时刻，wavefronts 排入队列中，等待执行。这
个例子中，只有 4 个 wavefronts（T0...T3）用于计算单元调度。
硬件限制了程序执行的活动 wavefront 数量，这依赖资源的使用情
况（例如活动寄存器使用的数量）。一个最佳可编程的计算设备通
常拥有多个活动的 wavefronts。

在运行时，wavefront T0 执行到 20 个周期；这时，由于内存取请
求发生了一个 stall。调度器接着开始执行下一个 wavefront T1。
Wavefront T1 执行，直到它被 stall 或执行完成。新的 wavefronts
开始执行，这个过程一直持续，直到达到可以利用的 wavefronts 的
数量。调度器然后返回地一个 wavefront 执行 T0。

如果 wavefront T0 等待的数据返回，T0 继续执行。在 Figure 2.8
的例子中，数据已经准备就绪，因此 T0 继续开始执行。由于有足够
的 wavefronts 和处理元素操作来填充较长的内存延迟，计算单元并
不会进入空闲（idle）状态。该内存延迟隐藏的方法帮助 GPU 计算
单元获得了最大的性能。

如果 T0-T3 中没有一个处于运行状态（就绪状态），计算单元等
待（stall），直到 T0-T3 中拥有一个 wavefront 就绪执行。在
Figure 2.9 中，T0 第一个开始继续执行。

问题：
我很行看看 wavefront 对应的指令序列？

