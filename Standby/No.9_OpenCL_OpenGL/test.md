14. GPU 架构和 OpenCL 模型的关系？OpenCL 如何在 GPU 硬件上运行？
特定 GPU上的优化技巧。图形架构和计算架构
- 关心计算架构而忽略其图形架构（图形架构在 OpenGL 中会涉及到）

R700 - Evergreen: VLIW5 执行引擎;
Radeon HD 6900（TeraScale3）: VLIW4
GCN：标量处理单元

问题：
什么是 VLIW5、VLIW4 执行引擎，以及标量处理单元？

Cayman 架构（VLIW4 执行引擎）

工作组 和 wavefront 的关系；
计算单元和 wavefront 的关系；

wavefront 可理解为 GPU 上的一个执行线程。
- 该线程是什么时候、如何调度的？
- 该线程可以同时操作的工作项数目？（可以对连续的 64 个工作项进行操作。分 4
个周期完成。即，每个周期只能完成 1/4 个 wavefront，即 16 个工作项）

这和 Caymen 架构有关，一个 SIMD 单元含有 16 个 SP，每个 SP 对应一个工作项；

每个工作组含有 4 条 wavefront。一个 SIMD 可对应多达 8 个工作组，一共 32 条
wavefront。这是为了访问外部存储器所带来的巨大延迟。
但是在执行时，一次只调度一条 wavefront 进行执行，4 个周期完成后再去调度其它
的 wavefront。因此，一条 wavefront 在 Cayman 中也被称为一个分支粒度（branch
 granularity）；

问题：
工作项在实际的 GPU 上是如何分配的？

如何利用 VLIW4 ？
编译器

注意：
一条 wavefront 也作为该 GPU 的分支粒度！


局部存储器

OpenCL 中的局部存储器对应与 GPU 中的 LDS，该 32KB 的 LDS 含有 32
个存储体（bank）。每个存储体具有 4 字节的宽度，以及 256 字节的深度。
这样一个存储体的容量正好是 32KB。

存储体冲突（bank co……）
访问同一个存储体的两个请求将会被先后顺序访问，而不能被并行访问。
最糟糕的情况是 16 个工作项都同时访问了同一个存储体，那么这 16 次
对 LDS 的访问都将被串行执行，从而造成 LDS 访问带宽的最低性能。

而 16 个工作项都访问了同一个地址，那么所请求都会被广播，不会造成存储体
冲突。

